{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "============\n",
    "\n",
    "Allen, R., & Vignoles, A. (2007). What should an index of school segregation measure? _Oxford Review of Education_, _33_(5), 643–668. https://doi.org/10.1080/03054980701366306\n",
    "\n",
    "Cohen, D. (2021). NYC School Segregation Report Card: Still Last, Action Needed Now! _Civil Rights Project/Proyecto Derechos Civiles_. UCLA. https://escholarship.org/uc/item/5fx616qn\n",
    "\n",
    "Frankel, D. M., & Volij, O. (2011). Measuring school segregation. _Journal of Economic Theory_, _146_(1), 1–38. https://doi.org/10.1016/j.jet.2010.10.008\n",
    "\n",
    "Lauren Lefty. (2021, February 11). [The Long Fight for Educational Equity in NYC](https://www.mcny.org/story/long-fight-educational-equity-nyc). _Museum of the City of New York_.\n",
    "\n",
    "Zhang, C. H., & Ruther, M. (2021). Contemporary patterns and issues of school segregation and white flight in U.S. metropolitan areas: Towards spatial inquiries. _GeoJournal_, _86_(3), 1511–1526. https://doi.org/10.1007/s10708-019-10122-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_id</th>\n",
       "      <th>asian_n</th>\n",
       "      <th>black_n</th>\n",
       "      <th>hispanic_n</th>\n",
       "      <th>white_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1275</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2619</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   school_id  asian_n  black_n  hispanic_n  white_n\n",
       "0       1275        2        0           4      169\n",
       "1       2619       14        1           2       20\n",
       "2         24        6       12          31     1247\n",
       "3         26        5       11          16      661\n",
       "4         27        6        2           3      365"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# load common core of schools data\n",
    "raw_data = pd.read_csv(\"_data/ccod-2007-ny_metro.csv\")\n",
    "data = raw_data.drop(columns=['school_id'])\n",
    "\n",
    "raw_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total from article 2,380,186\n",
      "   Total from data 181,380\n",
      "City D 0.52419646033252\n"
     ]
    }
   ],
   "source": [
    "# from Frankel & Volij\n",
    "public_school_pop_ny = 2380186\n",
    "\n",
    "# from Allen, R., & Vignoles, A. (2007)\n",
    "\n",
    "def calculate_dissimilarity(data):\n",
    "    total_black = data['black_n'].sum()\n",
    "    total_white = data['white_n'].sum()\n",
    "    total_asian = data['asian_n'].sum()\n",
    "    total_hispanic = data['hispanic_n'].sum()\n",
    "\n",
    "    total = sum([total_black, total_white, total_asian, total_hispanic])\n",
    "    print(f\"Total from article {public_school_pop_ny:,}\")\n",
    "    print(f\"   Total from data {total:,}\")\n",
    "\n",
    "    black_pct = total_black / total\n",
    "    white_pct = total_white / total\n",
    "    asian_pct = total_asian / total\n",
    "    hispanic_pct = total_hispanic / total\n",
    "\n",
    "    non_black = total - total_black\n",
    "    non_white = total - total_white\n",
    "    non_asian = total - total_asian\n",
    "    non_hispanic = total - total_hispanic\n",
    "\n",
    "    def diss(row, eth, eth_total, total):\n",
    "        cols = list(row.index)\n",
    "        # the total students in the school outside of the target ethnic group `eth`\n",
    "        non_eth = sum([row[col] for col in cols if col != eth and col.endswith('_n')])\n",
    "        D = (row[eth] / eth_total) - (non_eth / total)\n",
    "        return abs(D)\n",
    "\n",
    "    black_D = data.apply(partial(diss, eth=\"black_n\", eth_total=total_black, total=non_black), axis=1)\n",
    "    black_D = black_D.sum() / 2\n",
    "\n",
    "    white_D = data.apply(partial(diss, eth=\"white_n\", eth_total=total_white, total=non_white), axis=1)\n",
    "    white_D = white_D.sum() / 2\n",
    "\n",
    "    asian_D = data.apply(partial(diss, eth=\"asian_n\", eth_total=total_asian, total=non_asian), axis=1)\n",
    "    asian_D = asian_D.sum() / 2\n",
    "\n",
    "    hispanic_D = data.apply(partial(diss, eth=\"hispanic_n\", eth_total=total_hispanic, total=non_hispanic), axis=1)\n",
    "    hispanic_D = hispanic_D.sum() / 2\n",
    "\n",
    "    # calculated a weighted average of the D indices\n",
    "    weights = [asian_pct, black_pct, hispanic_pct, white_pct]\n",
    "    D = np.average([asian_D, black_D, hispanic_D, white_D], weights=weights)\n",
    "\n",
    "    return D\n",
    "\n",
    "nyc_D = calculate_dissimilarity(data)\n",
    "\n",
    "print(\"City D\", nyc_D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dissimilarity_index': 0.5328080086521683,\n",
       " 'simpson_interaction_index': 0.7005849431221257,\n",
       " 'dissimilarity_index_unnormalized': 0.37327726843659237}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# from Frankel, D. M., & Volij, O. (2011).\n",
    "ethnicity_cols = ['asian_n', 'black_n', 'hispanic_n', 'white_n']\n",
    "school_ethnicity_counts_df = (\n",
    "    raw_data[['school_id'] + ethnicity_cols]\n",
    "    .rename(columns={col: col.replace('_n', '') for col in ethnicity_cols})\n",
    "    .melt(id_vars=['school_id'], var_name='ethnicity', value_name='count')\n",
    "    .sort_values(['school_id', 'ethnicity'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "school_ethnicity_counts_df[\"count\"].sum()\n",
    "\n",
    "\n",
    "def dissimilarity_index(school_eth_counts: pd.DataFrame) -> dict:\n",
    "    # g --> group/ethnicity index\n",
    "    # n --> school index\n",
    "\n",
    "    N_g = school_eth_counts.groupby('ethnicity')['count'].sum()\n",
    "    N = N_g.sum()\n",
    "    P_g = (N_g / N)\n",
    "    I = (P_g * (1 - P_g)).sum()  # Simpson Interaction index\n",
    "    P_g = pd.DataFrame(P_g.rename('P'))\n",
    "    N_n = school_eth_counts.groupby('school_id')['count'].sum()\n",
    "    pi_n = pd.DataFrame((N_n / N).rename('pi'))\n",
    "    p_g_n = (\n",
    "        school_eth_counts\n",
    "        .groupby('school_id')\n",
    "        .apply(lambda df: df.set_index('ethnicity')['count'] / df['count'].sum())\n",
    "        .rename_axis([None], axis=1)\n",
    "        .reset_index()\n",
    "        .melt(id_vars=['school_id'], var_name='ethnicity', value_name='p')\n",
    "        .set_index(['school_id', 'ethnicity'])\n",
    "    )\n",
    "    r_g_n = p_g_n.join(P_g)\n",
    "    r_g_n = pd.DataFrame((r_g_n['p'] / r_g_n['P']).rename('r'))\n",
    "\n",
    "    # Dissimilarity index\n",
    "    d_g_n = r_g_n.join(pi_n).sort_index()\n",
    "    d_g_n = (d_g_n['r'] - 1).abs() * d_g_n['pi']\n",
    "    d_g = d_g_n.groupby('ethnicity').sum()\n",
    "    d_g = pd.DataFrame(d_g.rename('d')).join(P_g)\n",
    "    D = (d_g['d'] * d_g['P']).sum() / (2 * I)\n",
    "\n",
    "    return {\n",
    "        'dissimilarity_index': D,\n",
    "        'simpson_interaction_index': I,\n",
    "        'dissimilarity_index_unnormalized': I * D,\n",
    "    }\n",
    "\n",
    "\n",
    "dissimilarity_index(school_ethnicity_counts_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
